{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10cdc790-7e89-4521-a2b5-b7f93e3d1020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting konlpy\n",
      "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting JPype1>=0.7.0 (from konlpy)\n",
      "  Downloading jpype1-1.6.0-cp313-cp313-win_amd64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from konlpy) (5.3.0)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from konlpy) (2.1.3)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (24.2)\n",
      "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
      "   ---------------------------------------- 0.0/19.4 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 14.2/19.4 MB 79.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.4/19.4 MB 67.4 MB/s eta 0:00:00\n",
      "Downloading jpype1-1.6.0-cp313-cp313-win_amd64.whl (355 kB)\n",
      "Installing collected packages: JPype1, konlpy\n",
      "\n",
      "   ---------------------------------------- 0/2 [JPype1]\n",
      "   -------------------- ------------------- 1/2 [konlpy]\n",
      "   -------------------- ------------------- 1/2 [konlpy]\n",
      "   ---------------------------------------- 2/2 [konlpy]\n",
      "\n",
      "Successfully installed JPype1-1.6.0 konlpy-0.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "492edacc-699e-4b30-b46e-d0f24859bc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "엑셀 저장 완료 : Kurly Reviews.xlsx\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver    \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "from openpyxl import Workbook\n",
    "from konlpy.tag import Okt \n",
    "from collections import Counter\n",
    "import time \n",
    "\n",
    "# 크롬 드라이버 옵션 설정\n",
    "options = Options()\n",
    "options.add_argument(\"--no-sandbox\")    # 샌드박스 모드 비활성화\n",
    "options.add_argument(\"--disable-dev-shm-usage\")    # 공유 메모리 사용 비활성화\n",
    "options.add_argument(\"--headless\")    # 브라우저 창을 띄우지 않게\n",
    "\n",
    "# 크롬 드라이버 실행 (옵션 적용)\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "url = \"https://www.kurly.com/goods/1000078028\"\n",
    "test = driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "# print(soup)\n",
    "reviews = soup.select(\"p.css-y49dcn.e36z05c13\")\n",
    "\n",
    "#리스트 컴프리헨션으로 리뷰 태그에서 텍스트만 추출하고 공백 제거\n",
    "# review_lists는 리뷰 텍스트들의 리스트가 됨\n",
    "review_lists = [review.get_text().strip() for review in reviews]    #\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# 엑셀 워크북 생성\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = \"Kurly Reviews\"\n",
    "ws.append([\"리뷰내용\"])\n",
    "\n",
    "# 리뷰 텍스트 하나씩 엑셀에 행으로 추가\n",
    "for item in review_lists :\n",
    "    ws.append([item])   # 한 행에 리스트 형태로 넣음, 대괄호는 엑셀에 행 단위 데이터 입력용\n",
    "\n",
    "# 형태소 분석기 Okt객체 생성 (한국어 명사 추출용)\n",
    "okt = Okt()\n",
    "all_text = \" \".join(review_lists)   # 리스트의 리뷰들을 한 문장으로 합침 (공백기준)\n",
    "nouns = okt.nouns(all_text)   # 명사만 추출해서 리스트로 받음\n",
    "fiiltered_nouns = [n for n in nouns if len(nouns) > 1]   # 길이가 1보다 큰 명사만 필터링\n",
    "count = Counter(fiiltered_nouns)   # 단어별 등장 빈도 계산 \n",
    "\n",
    "ws_keywords = wb.create_sheet(\"Keyword Frequency\")   # 새로운 시트에 키워드 빈도수 저장\n",
    "ws_keywords.append([\"키워드\",\"빈도수\"])   # 제목 행추가\n",
    "for word, freq in count.most_common(30) :    # 빈도수 높은 순서대로 30개 단어와 빈도수 엑셀에 추가\n",
    "    ws_keywords.append([word, freq])\n",
    "\n",
    "wb.save(\"Kurly Reviews.xlsx\")\n",
    "print(\"엑셀 저장 완료 : Kurly Reviews.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01449f71-475b-4f85-89df-99aecf5c7372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료 : 전체 키워드 분석 결과 저장됨\n"
     ]
    }
   ],
   "source": [
    "from openpyxl import load_workbook   # 기존 엑셀파일 열기 위한 함수\n",
    "from konlpy.tag import Okt   # 한국어 자연어 처리 라이브러리, 형태소 분석 (키워드 분석 활용)\n",
    "from collections import Counter\n",
    "  \n",
    "wb = load_workbook(\"연관키워드 20250722 1448.xlsx\")   # 기존 저장된 엑셀 파일 불러옴\n",
    "ws = wb.active   # 현재 활성화된 첫번쨰 시트 사용\n",
    "\n",
    "# 각 행(row)에서 첫번째 셀 (row[0])만 추출\n",
    "# 아래 조건에 해당하는 모든 행들에 대해 반복하면서 엑셀 시트의 여러 행을 반복처리\n",
    "# 2행부터 시작 1열(A열)까지만 읽기 + 셀 값만 가져옴 if 첫 번째 셀 값이 비어 있지 않은 경우에\n",
    "texts = [row[0] for row in ws.iter_rows(min_row=2, max_col=1, values_only=True) if row[0]]\n",
    "\n",
    "okt = Okt()   # Okt 형태소 분석기 객체 생성\n",
    "all_text = \" \".join(texts)   # texts 리스트에 들어있는 문자열 공백 기준으로 하나의 문자열로 만듦\n",
    "nouns = okt.nouns(all_text)   # all_text에서 명사들만 추출하여 리스트로 반환\n",
    "filtered_nouns = [n for n in nouns if len(n) > 1]   # \n",
    "count = Counter(filtered_nouns)\n",
    "\n",
    "ws_keywords = wb.create_sheet(\"키워드 전체분석\")\n",
    "ws_keywords.append([\"명사\", \"빈도수\"])\n",
    "for word, freq in sorted(count.items(), key=lambda x:x[1], reverse=True) :\n",
    "    ws_keywords.append([word, freq])\n",
    "\n",
    "wb.save(\"연관키워드_분석결과.xlsx\")\n",
    "print(\"완료 : 전체 키워드 분석 결과 저장됨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd78f2ab-968b-4a87-8750-a66977c3ff4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료 : 전체 키워드 분석 결과 저장됨\n"
     ]
    }
   ],
   "source": [
    "# 실습\n",
    "from openpyxl import load_workbook\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "\n",
    "wb = load_workbook(\"연관키워드 20250722 1550.xlsx\")\n",
    "ws = wb.active\n",
    "\n",
    "texts = [row[0] for row in ws.iter_rows(min_row=2, max_col=1, values_only=True) if row[0]]\n",
    "\n",
    "okt=Okt()\n",
    "all_text = \" \".join(texts)\n",
    "nouns = okt.nouns(all_text)\n",
    "filtered_nouns = [n for n in nouns if len(n) > 1]\n",
    "count = Counter(filtered_nouns)\n",
    "\n",
    "ws_keywords = wb.create_sheet(\"키워드 전체분석\")\n",
    "ws_keywords.append([\"명사\", \"빈도수\"])\n",
    "for word, freq in sorted(count.items(), key=lambda x:x[1], reverse = True) :\n",
    "    ws_keywords.append([word, freq])\n",
    "\n",
    "wb.save(\"연관키워드_분석결과 수빈.xlsx\")\n",
    "print(\"완료 : 전체 키워드 분석 결과 저장됨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "487ee7d4-feda-45dd-b55f-f8a1160f6e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료 : 전체 키워드 분석 결과 저장됨\n"
     ]
    }
   ],
   "source": [
    "from openpyxl import load_workbook   # 기존 엑셀파일 열기 위한 함수\n",
    "from konlpy.tag import Okt   # 한국어 자연어 처리 라이브러리, 형태소 분석 (키워드 분석 활용)\n",
    "from collections import Counter\n",
    "import re\n",
    "  \n",
    "wb = load_workbook(\"연관키워드 20250722 1448.xlsx\")   # 기존 저장된 엑셀 파일 불러옴\n",
    "ws = wb.active   # 현재 활성화된 첫번쨰 시트 사용\n",
    "\n",
    "# 각 행(row)에서 첫번째 셀 (row[0])만 추출\n",
    "# 아래 조건에 해당하는 모든 행들에 대해 반복하면서 엑셀 시트의 여러 행을 반복처리\n",
    "# 2행부터 시작 1열(A열)까지만 읽기 + 셀 값만 가져옴 if 첫 번째 셀 값이 비어 있지 않은 경우에\n",
    "texts = [row[0] for row in ws.iter_rows(min_row=2, max_col=1, values_only=True) if row[0]]\n",
    "\n",
    "okt = Okt()   # Okt 형태소 분석기 객체 생성\n",
    "all_text = \" \".join(texts)   # texts 리스트에 들어있는 문자열 공백 기준으로 하나의 문자열로 만듦\n",
    "\n",
    "nouns_tokens = okt.nouns(all_text)    # 전체 텍스트에 명사만 추출\n",
    "\n",
    "regex_tokens = re.findall(r'[A-Za-z]*\\d+[A-Za-z]+|\\d+[A-Za-z]*',all_text)   # 정규 표현식 숫자+영문 조합 추출\n",
    "\n",
    "valid_one_letter = {\"금\", \"은\", \"동\"}   # 의미있는 한글자 단어들 허용\n",
    "stopwords = {\"사용\", \"정도\", \"조금\", \"제품\", \"때문\", \"생각\", \"만족\", \"구매\", \"다음\"}   # 분석에서 제외할 용어 설정\n",
    "\n",
    "combined_tokens = nouns_tokens + regex_tokens\n",
    "filtered_tokens = [t for t in combined_tokens if (len(t) > 1 or t in valid_one_letter) and t not in stopwords]   #\n",
    "\n",
    "count = Counter(filtered_tokens)\n",
    "\n",
    "ws_keywords = wb.create_sheet(\"키워드 전체분석\")\n",
    "ws_keywords.append([\"명사\", \"빈도수\"])\n",
    "for word, freq in sorted(count.items(), key=lambda x:x[1], reverse=True) :\n",
    "    ws_keywords.append([word, freq])\n",
    "\n",
    "wb.save(\"연관키워드_분석결과.xlsx\")\n",
    "print(\"완료 : 전체 키워드 분석 결과 저장됨\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
